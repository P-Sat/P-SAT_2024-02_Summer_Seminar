{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oos2bngATs2R",
        "outputId": "a5e1534d-afeb-41c7-9805-86e94880741d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tsfresh in /usr/local/lib/python3.10/dist-packages (0.20.2)\n",
            "Requirement already satisfied: requests>=2.9.1 in /usr/local/lib/python3.10/dist-packages (from tsfresh) (2.31.0)\n",
            "Requirement already satisfied: numpy>=1.15.1 in /usr/local/lib/python3.10/dist-packages (from tsfresh) (1.25.2)\n",
            "Requirement already satisfied: pandas>=0.25.0 in /usr/local/lib/python3.10/dist-packages (from tsfresh) (2.0.3)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from tsfresh) (1.11.4)\n",
            "Requirement already satisfied: statsmodels>=0.13 in /usr/local/lib/python3.10/dist-packages (from tsfresh) (0.14.2)\n",
            "Requirement already satisfied: patsy>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from tsfresh) (0.5.6)\n",
            "Requirement already satisfied: scikit-learn>=0.22.0 in /usr/local/lib/python3.10/dist-packages (from tsfresh) (1.2.2)\n",
            "Requirement already satisfied: tqdm>=4.10.0 in /usr/local/lib/python3.10/dist-packages (from tsfresh) (4.66.4)\n",
            "Requirement already satisfied: stumpy>=1.7.2 in /usr/local/lib/python3.10/dist-packages (from tsfresh) (1.13.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from tsfresh) (2.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.25.0->tsfresh) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.25.0->tsfresh) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.25.0->tsfresh) (2024.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy>=0.4.1->tsfresh) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.9.1->tsfresh) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.9.1->tsfresh) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.9.1->tsfresh) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.9.1->tsfresh) (2024.7.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22.0->tsfresh) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22.0->tsfresh) (3.5.0)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from statsmodels>=0.13->tsfresh) (24.1)\n",
            "Requirement already satisfied: numba>=0.57.1 in /usr/local/lib/python3.10/dist-packages (from stumpy>=1.7.2->tsfresh) (0.58.1)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.57.1->stumpy>=1.7.2->tsfresh) (0.41.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install tsfresh"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ebws1qMvspLO"
      },
      "source": [
        "PREPROCESSING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "collapsed": true,
        "id": "41hqgHehS-DR",
        "outputId": "cf45ea0a-92d8-4fa2-8565-3e43dc3ab045"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tsfresh.feature_extraction.settings:Dependency not available for matrix_profile, this feature will be disabled!\n",
            "Feature Extraction: 100%|██████████| 13000/13000 [1:34:35<00:00,  2.29it/s]\n",
            "WARNING:tsfresh.feature_extraction.settings:Dependency not available for matrix_profile, this feature will be disabled!\n",
            "Feature Extraction: 100%|██████████| 2000/2000 [14:12<00:00,  2.34it/s]\n"
          ]
        },
        {
          "ename": "KeyError",
          "evalue": "'Year'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3652\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3653\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3654\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Year'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-2b186e947ac8>\u001b[0m in \u001b[0;36m<cell line: 118>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Year_encoded'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Country_encoded'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'S/N_encoded'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m \u001b[0mtrain_encoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencode_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_category\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0mtest_encoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencode_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_category\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-2b186e947ac8>\u001b[0m in \u001b[0;36mencode_data\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mencode_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0mbins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1990\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2010\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2020\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Year_encoded'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdigitize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Year'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbins\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     df['Country'] = df['Country'].replace({\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3759\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3761\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3762\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3763\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3653\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3654\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3655\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3656\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3657\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Year'"
          ]
        }
      ],
      "source": [
        "# 패키지 로드\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.signal import find_peaks\n",
        "from tsfresh import extract_features, select_features\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.utils.class_weight import compute_sample_weight\n",
        "\n",
        "# 시드 설정\n",
        "SEED = 1234\n",
        "\n",
        "# 시간 측정 시작\n",
        "start = time.time()\n",
        "\n",
        "# 데이터 로드\n",
        "train = pd.read_csv(\"train.csv\")\n",
        "test = pd.read_csv(\"test.csv\")\n",
        "sample_submission = pd.read_csv(\"sample_submission.csv\")\n",
        "\n",
        "# 시계열 데이터 하나의 행의 결측치를 주기 기반으로 보간하는 함수 정의\n",
        "def periodic_interpolation(series, period):\n",
        "    interpolated_series = series.copy()\n",
        "    for i in range(len(series)):\n",
        "        if np.isnan(series[i]):\n",
        "            previous_values = []\n",
        "            for j in range(i % period, len(series), period):\n",
        "                if not np.isnan(series[j]):\n",
        "                    previous_values.append(series[j])\n",
        "            if previous_values:\n",
        "                interpolated_series[i] = np.mean(previous_values)\n",
        "    return interpolated_series\n",
        "\n",
        "# 데이터프레임의 모든 시계열 데이터에 대해 주기 기반 보간을 적용하는 함수\n",
        "def apply_periodic_interpolation(df):\n",
        "    for idx in df.index:\n",
        "        first_time_series = df.iloc[idx, 1:501].values\n",
        "\n",
        "        # 주기 감지\n",
        "        peaks, _ = find_peaks(first_time_series, distance=100)\n",
        "        periods = np.diff(peaks)\n",
        "        if len(periods) > 0:\n",
        "            period = int(np.median(periods))  # 주기 길이를 중앙값으로 설정\n",
        "\n",
        "            # 주기 기반 보간 적용\n",
        "            interpolated_series = periodic_interpolation(first_time_series, period)\n",
        "\n",
        "            # 보간된 결과를 원래 데이터프레임에 반영\n",
        "            df.iloc[idx, 1:501] = interpolated_series\n",
        "        else:\n",
        "            print(f\"Warning: No peaks detected for row {idx}. Skipping interpolation.\")\n",
        "    return df\n",
        "\n",
        "# 결측치 보간 함수 적용\n",
        "train_indexed = train.iloc[:, 1:501]\n",
        "test_indexed = test.iloc[:, 1:501]\n",
        "train_nomissing = apply_periodic_interpolation(train_indexed)\n",
        "test_nomissing = apply_periodic_interpolation(test_indexed)\n",
        "\n",
        "# tsfresh를 사용한 특징 추출\n",
        "time_series_data = train_nomissing.copy().reset_index()\n",
        "time_series_data = pd.melt(time_series_data, id_vars=['index'], var_name='time', value_name='value')\n",
        "time_series_data.rename(columns={'index': 'id'}, inplace=True)\n",
        "\n",
        "# 특징 추출\n",
        "features = extract_features(time_series_data, column_id='id', column_sort='time')\n",
        "fe1 = features\n",
        "fe2 = fe1.dropna(axis=1)\n",
        "\n",
        "# 라벨과 특징 데이터 준비\n",
        "X = fe2\n",
        "y = train['Label']\n",
        "\n",
        "# 같은 방법으로 test_nomissing 의 특징 추출을 위한 전처리 적용\n",
        "time_series_test = test_nomissing.copy().reset_index()\n",
        "time_series_test = pd.melt(time_series_test, id_vars=['index'], var_name='time', value_name='value')\n",
        "time_series_test.rename(columns={'index': 'id'}, inplace=True)\n",
        "\n",
        "# 특징 추출\n",
        "features = extract_features(time_series_test, column_id='id', column_sort='time')\n",
        "fe1t = features\n",
        "fe2t = fe1t.dropna(axis=1)\n",
        "\n",
        "# TSfresh를 활용한 변수 선택\n",
        "relevant_features = select_features(fe2, y, multiclass=True, n_significant=3, ml_task='classification')\n",
        "X = fe2[relevant_features.columns]\n",
        "\n",
        "# 범주형 컬럼 인코딩 함수 정의\n",
        "def encode_data(df):\n",
        "    bins = [1990, 2000, 2010, 2020]\n",
        "    df['Year_encoded'] = np.digitize(df['Year'], bins=bins) - 1\n",
        "\n",
        "    df['Country'] = df['Country'].replace({\n",
        "        '중국': 'CHN', '美国': 'USA', 'china': 'CHN', '中国': 'CHN', 'Korea': 'KOR',\n",
        "        'america': 'USA', '미국': 'USA', 'U.S.': 'USA', '대한민국': 'KOR', '韩国': 'KOR',\n",
        "        'South Korea': 'KOR', '한국': 'KOR'\n",
        "    })\n",
        "    country_mapping = {'KOR': 0, 'CHN': 1, 'USA': 2}\n",
        "    df['Country_encoded'] = df['Country'].map(country_mapping)\n",
        "\n",
        "    df['S/N_encoded'] = df['S/N'].str[:4].apply(lambda x: 0 if x == 'PSCG' else (1 if x == 'PSFT' else -1))\n",
        "\n",
        "    return df[['Year_encoded', 'Country_encoded', 'S/N_encoded']]\n",
        "\n",
        "train_encoded = encode_data(train)\n",
        "test_encoded = encode_data(test)\n",
        "\n",
        "X = pd.concat([X, train_encoded], axis=1)\n",
        "\n",
        "# 수치형 컬럼과 범주형 컬럼 나누기\n",
        "def identify_feature_types(df, threshold=3):\n",
        "    categorical_features = []\n",
        "    continuous_features = []\n",
        "    for col in df.columns:\n",
        "        if df[col].nunique() <= threshold:\n",
        "            categorical_features.append(col)\n",
        "        else:\n",
        "            continuous_features.append(col)\n",
        "    return categorical_features, continuous_features\n",
        "\n",
        "categorical_features, continuous_features = identify_feature_types(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cuy7VAh9V63z"
      },
      "source": [
        "MODELING(OPTUNA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DhkL2-o1cYCg",
        "outputId": "c2be4eca-e536-4b16-b28f-596e92481eb1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-3.6.1-py3-none-any.whl (380 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m380.1/380.1 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.13.2-py3-none-any.whl (232 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.0/233.0 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.8.2-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (24.1)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.31)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.66.4)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.1)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna)\n",
            "  Downloading Mako-1.3.5-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (3.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.5)\n",
            "Installing collected packages: Mako, colorlog, alembic, optuna\n",
            "Successfully installed Mako-1.3.5 alembic-1.13.2 colorlog-6.8.2 optuna-3.6.1\n"
          ]
        }
      ],
      "source": [
        "!pip install optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AUGCdgKtTaRS",
        "outputId": "f9bb74ca-8207-4629-a6ff-d3e4e95915c2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-07-19 11:31:43,765] A new study created in memory with name: no-name-41e2398b-a21b-456a-95c8-6bfdee066b09\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2024-07-19 11:33:19,746] Trial 0 finished with value: 0.9834615384615385 and parameters: {'n_estimators': 416, 'learning_rate': 0.08437782175702015, 'max_depth': 7, 'colsample_bytree': 0.9383018053724173, 'subsample': 0.9083475006942705, 'alpha': 0.8424939450365576, 'lambda': 5.2405600831397905}. Best is trial 0 with value: 0.9834615384615385.\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2024-07-19 11:33:54,968] Trial 1 finished with value: 0.9746153846153847 and parameters: {'n_estimators': 260, 'learning_rate': 0.1293825381073609, 'max_depth': 4, 'colsample_bytree': 0.9131327278088507, 'subsample': 0.550548939744332, 'alpha': 7.358254749087157, 'lambda': 8.75715031805688}. Best is trial 0 with value: 0.9834615384615385.\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2024-07-19 11:34:52,316] Trial 2 finished with value: 0.9773076923076923 and parameters: {'n_estimators': 980, 'learning_rate': 0.12293378279989135, 'max_depth': 10, 'colsample_bytree': 0.9373261124781112, 'subsample': 0.8799493157738281, 'alpha': 7.575513982611932, 'lambda': 9.995394814291707}. Best is trial 0 with value: 0.9834615384615385.\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2024-07-19 11:35:24,862] Trial 3 finished with value: 0.9823076923076923 and parameters: {'n_estimators': 829, 'learning_rate': 0.20080129761550658, 'max_depth': 7, 'colsample_bytree': 0.6755773058452675, 'subsample': 0.7195187603145808, 'alpha': 2.5604246954381793, 'lambda': 6.257320512983199}. Best is trial 0 with value: 0.9834615384615385.\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2024-07-19 11:36:01,260] Trial 4 finished with value: 0.9761538461538461 and parameters: {'n_estimators': 463, 'learning_rate': 0.15358967617840527, 'max_depth': 3, 'colsample_bytree': 0.766347890011253, 'subsample': 0.5556709773478133, 'alpha': 7.120834794296044, 'lambda': 4.134436130568774}. Best is trial 0 with value: 0.9834615384615385.\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2024-07-19 11:37:02,921] Trial 5 finished with value: 0.98 and parameters: {'n_estimators': 673, 'learning_rate': 0.06705071645603534, 'max_depth': 4, 'colsample_bytree': 0.6552775473040433, 'subsample': 0.8059881453632916, 'alpha': 6.49688491585041, 'lambda': 0.35556132860625644}. Best is trial 0 with value: 0.9834615384615385.\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2024-07-19 11:37:50,420] Trial 6 finished with value: 0.98 and parameters: {'n_estimators': 245, 'learning_rate': 0.06942422717946796, 'max_depth': 6, 'colsample_bytree': 0.6068922673334676, 'subsample': 0.9145034866976594, 'alpha': 2.5486059929685734, 'lambda': 2.972520210015639}. Best is trial 0 with value: 0.9834615384615385.\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2024-07-19 11:38:32,359] Trial 7 finished with value: 0.9857692307692307 and parameters: {'n_estimators': 396, 'learning_rate': 0.1769788067384396, 'max_depth': 4, 'colsample_bytree': 0.6600678280598793, 'subsample': 0.5738444139743181, 'alpha': 1.9066573470658332, 'lambda': 6.917202096775795}. Best is trial 7 with value: 0.9857692307692307.\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2024-07-19 11:39:13,127] Trial 8 finished with value: 0.9780769230769231 and parameters: {'n_estimators': 755, 'learning_rate': 0.1521595037788567, 'max_depth': 10, 'colsample_bytree': 0.9707994036176881, 'subsample': 0.8512619270679578, 'alpha': 7.709154546430489, 'lambda': 1.5719203977063312}. Best is trial 7 with value: 0.9857692307692307.\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2024-07-19 11:41:04,499] Trial 9 finished with value: 0.9792307692307692 and parameters: {'n_estimators': 562, 'learning_rate': 0.05880799536477113, 'max_depth': 9, 'colsample_bytree': 0.911201196519293, 'subsample': 0.7559829104568385, 'alpha': 5.370290094661561, 'lambda': 9.087865911644808}. Best is trial 7 with value: 0.9857692307692307.\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2024-07-19 11:41:23,264] Trial 10 finished with value: 0.9807692307692307 and parameters: {'n_estimators': 133, 'learning_rate': 0.28982119004558515, 'max_depth': 5, 'colsample_bytree': 0.5502458196392903, 'subsample': 0.6516004996516734, 'alpha': 2.9672967382266897, 'lambda': 7.043655848307037}. Best is trial 7 with value: 0.9857692307692307.\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2024-07-19 11:42:17,521] Trial 11 finished with value: 0.9853846153846154 and parameters: {'n_estimators': 438, 'learning_rate': 0.22125502911151262, 'max_depth': 7, 'colsample_bytree': 0.8130350525687551, 'subsample': 0.9956163396307386, 'alpha': 0.3755360570281401, 'lambda': 5.862654049128812}. Best is trial 7 with value: 0.9857692307692307.\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2024-07-19 11:43:23,974] Trial 12 finished with value: 0.985 and parameters: {'n_estimators': 364, 'learning_rate': 0.2230279347401734, 'max_depth': 8, 'colsample_bytree': 0.7865764147663238, 'subsample': 0.9881187036925801, 'alpha': 0.14230008241414768, 'lambda': 7.340397985187606}. Best is trial 7 with value: 0.9857692307692307.\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2024-07-19 11:43:52,180] Trial 13 finished with value: 0.9792307692307692 and parameters: {'n_estimators': 538, 'learning_rate': 0.22148787149314209, 'max_depth': 6, 'colsample_bytree': 0.8299573577644294, 'subsample': 0.6375145489868719, 'alpha': 9.534078585336998, 'lambda': 4.979901090679863}. Best is trial 7 with value: 0.9857692307692307.\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2024-07-19 11:44:44,727] Trial 14 finished with value: 0.9376923076923077 and parameters: {'n_estimators': 309, 'learning_rate': 0.010492242978771466, 'max_depth': 5, 'colsample_bytree': 0.7013069090666457, 'subsample': 0.6357079350439077, 'alpha': 1.1513161734734636, 'lambda': 7.874408144388793}. Best is trial 7 with value: 0.9857692307692307.\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2024-07-19 11:45:15,081] Trial 15 finished with value: 0.9796153846153847 and parameters: {'n_estimators': 586, 'learning_rate': 0.28092646005065214, 'max_depth': 8, 'colsample_bytree': 0.8452362101825794, 'subsample': 0.5042095483058568, 'alpha': 4.117141489640082, 'lambda': 5.830801570980473}. Best is trial 7 with value: 0.9857692307692307.\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2024-07-19 11:45:25,730] Trial 16 finished with value: 0.9738461538461538 and parameters: {'n_estimators': 123, 'learning_rate': 0.19650181267913214, 'max_depth': 3, 'colsample_bytree': 0.5116611001583959, 'subsample': 0.7126041165811876, 'alpha': 1.469295836548258, 'lambda': 3.6640902508609337}. Best is trial 7 with value: 0.9857692307692307.\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2024-07-19 11:45:45,626] Trial 17 finished with value: 0.9853846153846154 and parameters: {'n_estimators': 473, 'learning_rate': 0.2538810061749678, 'max_depth': 5, 'colsample_bytree': 0.7105268248497691, 'subsample': 0.9591008358688675, 'alpha': 3.9150470830285773, 'lambda': 6.5428899630051855}. Best is trial 7 with value: 0.9857692307692307.\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2024-07-19 11:46:32,108] Trial 18 finished with value: 0.9842307692307692 and parameters: {'n_estimators': 648, 'learning_rate': 0.1880435787993013, 'max_depth': 8, 'colsample_bytree': 0.612523411687656, 'subsample': 0.7912815808369913, 'alpha': 1.8093020776196596, 'lambda': 8.163217365082343}. Best is trial 7 with value: 0.9857692307692307.\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2024-07-19 11:46:58,706] Trial 19 finished with value: 0.9865384615384616 and parameters: {'n_estimators': 349, 'learning_rate': 0.24969363279482715, 'max_depth': 4, 'colsample_bytree': 0.815663133685939, 'subsample': 0.5911581132268362, 'alpha': 0.09450215711260918, 'lambda': 2.5538161643061583}. Best is trial 19 with value: 0.9865384615384616.\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2024-07-19 11:47:18,129] Trial 20 finished with value: 0.9838461538461538 and parameters: {'n_estimators': 216, 'learning_rate': 0.26070513198412176, 'max_depth': 4, 'colsample_bytree': 0.7350300099447299, 'subsample': 0.6029174157306894, 'alpha': 3.7620609359977895, 'lambda': 2.04998193006642}. Best is trial 19 with value: 0.9865384615384616.\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2024-07-19 11:47:57,381] Trial 21 finished with value: 0.9853846153846154 and parameters: {'n_estimators': 356, 'learning_rate': 0.24250470907080937, 'max_depth': 6, 'colsample_bytree': 0.8371794952179199, 'subsample': 0.5761766419048779, 'alpha': 0.09495583648753722, 'lambda': 4.501624260205442}. Best is trial 19 with value: 0.9865384615384616.\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2024-07-19 11:48:34,801] Trial 22 finished with value: 0.9876923076923076 and parameters: {'n_estimators': 433, 'learning_rate': 0.17544298336548947, 'max_depth': 3, 'colsample_bytree': 0.7979479822008998, 'subsample': 0.6814118250794118, 'alpha': 0.07158768442748387, 'lambda': 2.8854317762003943}. Best is trial 22 with value: 0.9876923076923076.\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2024-07-19 11:49:05,435] Trial 23 finished with value: 0.9842307692307692 and parameters: {'n_estimators': 372, 'learning_rate': 0.17934135010270874, 'max_depth': 3, 'colsample_bytree': 0.873800168030509, 'subsample': 0.6797094081977568, 'alpha': 1.915083995164881, 'lambda': 2.252041896993285}. Best is trial 22 with value: 0.9876923076923076.\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2024-07-19 11:49:59,791] Trial 24 finished with value: 0.9857692307692307 and parameters: {'n_estimators': 498, 'learning_rate': 0.11995062761293887, 'max_depth': 4, 'colsample_bytree': 0.7558601153419138, 'subsample': 0.5034134051074284, 'alpha': 0.9165435375176878, 'lambda': 0.9066625199326275}. Best is trial 22 with value: 0.9876923076923076.\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2024-07-19 11:50:22,980] Trial 25 finished with value: 0.9803846153846154 and parameters: {'n_estimators': 294, 'learning_rate': 0.16317177240757483, 'max_depth': 3, 'colsample_bytree': 0.6314276987936401, 'subsample': 0.5990557314085677, 'alpha': 2.1493562168518725, 'lambda': 3.2011799125359257}. Best is trial 22 with value: 0.9876923076923076.\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2024-07-19 11:50:52,845] Trial 26 finished with value: 0.9834615384615385 and parameters: {'n_estimators': 200, 'learning_rate': 0.17094302791270513, 'max_depth': 5, 'colsample_bytree': 0.5701998656257866, 'subsample': 0.679240179570147, 'alpha': 0.9373730381341312, 'lambda': 2.578313768364288}. Best is trial 22 with value: 0.9876923076923076.\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2024-07-19 11:51:33,451] Trial 27 finished with value: 0.9811538461538462 and parameters: {'n_estimators': 400, 'learning_rate': 0.14266469194717837, 'max_depth': 4, 'colsample_bytree': 0.7997097910665804, 'subsample': 0.5488998080956652, 'alpha': 3.1655263479306424, 'lambda': 1.342285177888148}. Best is trial 22 with value: 0.9876923076923076.\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2024-07-19 11:52:21,661] Trial 28 finished with value: 0.9807692307692307 and parameters: {'n_estimators': 632, 'learning_rate': 0.10087076532556435, 'max_depth': 3, 'colsample_bytree': 0.8764701446984292, 'subsample': 0.5887032979791695, 'alpha': 5.000591974793351, 'lambda': 0.10995346152886665}. Best is trial 22 with value: 0.9876923076923076.\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "[I 2024-07-19 11:52:59,317] Trial 29 finished with value: 0.9873076923076923 and parameters: {'n_estimators': 331, 'learning_rate': 0.23609317478558609, 'max_depth': 4, 'colsample_bytree': 0.7174146159124657, 'subsample': 0.6723248327796904, 'alpha': 0.547464183487794, 'lambda': 5.024797974409836}. Best is trial 22 with value: 0.9876923076923076.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best trial:\n",
            "  Accuracy: 0.9876923076923076\n",
            "  Best hyperparameters:  {'n_estimators': 433, 'learning_rate': 0.17544298336548947, 'max_depth': 3, 'colsample_bytree': 0.7979479822008998, 'subsample': 0.6814118250794118, 'alpha': 0.07158768442748387, 'lambda': 2.8854317762003943}\n"
          ]
        }
      ],
      "source": [
        "# 데이터 분할\n",
        "x_train, x_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=SEED)\n",
        "\n",
        "# RobustScaler 적용\n",
        "scaler = RobustScaler()\n",
        "x_train_scale = scaler.fit_transform(x_train[continuous_features])\n",
        "x_val_scale = scaler.transform(x_val[continuous_features])\n",
        "\n",
        "X_continuous_df = pd.DataFrame(x_train_scale, index=x_train.index, columns=continuous_features)\n",
        "x_val_continuous_df = pd.DataFrame(x_val_scale, index=x_val.index, columns=continuous_features)\n",
        "\n",
        "# 최종 데이터셋\n",
        "train_set = pd.concat([x_train[categorical_features], X_continuous_df], axis=1)\n",
        "test_set = pd.concat([x_val[categorical_features], x_val_continuous_df], axis=1)\n",
        "\n",
        "# 모델 학습\n",
        "import optuna\n",
        "from xgboost import XGBClassifier\n",
        "def objective(trial):\n",
        "    param = {\n",
        "        'verbosity': 1,\n",
        "        'objective': 'multi:softprob',\n",
        "        'eval_metric': 'mlogloss',\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
        "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
        "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
        "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
        "        'alpha': trial.suggest_float('alpha', 0, 10),\n",
        "        'lambda': trial.suggest_float('lambda', 0, 10)\n",
        "    }\n",
        "\n",
        "    sample_weights = compute_sample_weight(class_weight='balanced', y=y_train)\n",
        "    model = XGBClassifier(**param, random_state=SEED)\n",
        "    model.fit(train_set, y_train, eval_set=[(test_set, y_val)], early_stopping_rounds=10, sample_weight=sample_weights, verbose=False)\n",
        "\n",
        "    preds = model.predict(test_set)\n",
        "    acc = np.mean(preds == y_val)\n",
        "\n",
        "    return acc\n",
        "\n",
        "# 옵튜나 실행\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=30)\n",
        "\n",
        "print(\"Best trial:\")\n",
        "trial = study.best_trial\n",
        "\n",
        "print(f\"  Accuracy: {trial.value}\")\n",
        "print(\"  Best hyperparameters: \", trial.params)\n",
        "\n",
        "# 베스트 하이퍼파라미터\n",
        "best_params = trial.params\n",
        "model = XGBClassifier(**best_params, eval_metric='mlogloss', random_state=SEED)\n",
        "middle = time.time()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DCI8drr21vYy",
        "outputId": "4ccad67c-d5ac-4b0a-e544-33ac955d30ab"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'n_estimators': 433,\n",
              " 'learning_rate': 0.17544298336548947,\n",
              " 'max_depth': 3,\n",
              " 'colsample_bytree': 0.7979479822008998,\n",
              " 'subsample': 0.6814118250794118,\n",
              " 'alpha': 0.07158768442748387,\n",
              " 'lambda': 2.8854317762003943}"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_params"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8CWbrE6BYyRK"
      },
      "source": [
        "MODELING WITH BEST PARAMETER"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "id": "3xYa2o7TaRqO",
        "outputId": "14b3ddaa-3561-469e-97f3-9c52a24a7531"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(alpha=0.07158768442748387, base_score=None, booster=None,\n",
              "              callbacks=None, colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=0.7979479822008998, device=None,\n",
              "              early_stopping_rounds=None, enable_categorical=False,\n",
              "              eval_metric=&#x27;mlogloss&#x27;, feature_types=None, gamma=None,\n",
              "              grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, lambda=2.8854317762003943,\n",
              "              learning_rate=0.17544298336548947, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=3, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              multi_strategy=None, n_estimators=433, n_jobs=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(alpha=0.07158768442748387, base_score=None, booster=None,\n",
              "              callbacks=None, colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=0.7979479822008998, device=None,\n",
              "              early_stopping_rounds=None, enable_categorical=False,\n",
              "              eval_metric=&#x27;mlogloss&#x27;, feature_types=None, gamma=None,\n",
              "              grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, lambda=2.8854317762003943,\n",
              "              learning_rate=0.17544298336548947, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=3, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              multi_strategy=None, n_estimators=433, n_jobs=None, ...)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "XGBClassifier(alpha=0.07158768442748387, base_score=None, booster=None,\n",
              "              callbacks=None, colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=0.7979479822008998, device=None,\n",
              "              early_stopping_rounds=None, enable_categorical=False,\n",
              "              eval_metric='mlogloss', feature_types=None, gamma=None,\n",
              "              grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, lambda=2.8854317762003943,\n",
              "              learning_rate=0.17544298336548947, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=3, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              multi_strategy=None, n_estimators=433, n_jobs=None, ...)"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_params = {'n_estimators': 433,\n",
        "               'learning_rate': 0.17544298336548947,\n",
        "               'max_depth': 3,\n",
        "               'colsample_bytree': 0.7979479822008998,\n",
        "               'subsample': 0.6814118250794118,\n",
        "               'alpha': 0.07158768442748387,\n",
        "               'lambda': 2.8854317762003943}\n",
        "\n",
        "model = XGBClassifier(**best_params, eval_metric='mlogloss', random_state=SEED)\n",
        "\n",
        "fe2t_t = fe2t[relevant_features.columns]\n",
        "t = pd.concat([fe2t_t, test_encoded], axis=1)\n",
        "\n",
        "scaler = RobustScaler()\n",
        "x_train_scale = scaler.fit_transform(X[continuous_features])\n",
        "x_test_scale = scaler.transform(t[continuous_features])\n",
        "\n",
        "X_continuous_df = pd.DataFrame(x_train_scale, index=X.index, columns=continuous_features)\n",
        "x_test_continuous_df = pd.DataFrame(x_test_scale, index=t.index, columns=continuous_features)\n",
        "\n",
        "train_set = pd.concat([X[categorical_features], X_continuous_df], axis=1)\n",
        "test_set = pd.concat([t[categorical_features], x_test_continuous_df], axis=1)\n",
        "\n",
        "sample_weights = compute_sample_weight(class_weight='balanced', y=y)\n",
        "model.fit(train_set, y, sample_weight=sample_weights)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wp4D1dsXs7hY"
      },
      "source": [
        "PREDICT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E-cyQlGoXjPl",
        "outputId": "99b28f7c-0a64-41c7-e8da-d14cd292fcf9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "전체 실행 시간: 8914.377143144608 초\n",
            "모델 학습 시간: 8685.92897939682 초\n",
            "예측 및 파일 생성 시간: 228.44816374778748 초\n"
          ]
        }
      ],
      "source": [
        "# 예측\n",
        "y_test_pred = model.predict(test_set)\n",
        "y_test_pred_series = pd.Series(y_test_pred)\n",
        "\n",
        "# 제출 파일 생성\n",
        "submission_df = sample_submission.copy()\n",
        "submission_df['Label'] = y_test_pred_series\n",
        "submission_df.to_csv('submission_result_xgb_fffinal_optuna.csv', index=False)\n",
        "\n",
        "# 전체 시간 측정 종료\n",
        "end = time.time()\n",
        "\n",
        "# 시간 출력\n",
        "print(f\"전체 실행 시간: {end - start} 초\")\n",
        "print(f\"모델 학습 시간: {middle - start} 초\")\n",
        "print(f\"예측 및 파일 생성 시간: {end - middle} 초\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
